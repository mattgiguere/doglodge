{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scrapy.spiders import BaseSpider\n",
    "from scrapy.selector import HtmlXPathSelector\n",
    "from scrapy.http import Request\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# url string components for reviewer pages\n",
    "URL_BASE = 'http://www.bringfido.com/'\n",
    "\n",
    "# yelp unique url endings for each restaurant\n",
    "CITIES = ['new_haven_ct_us',\n",
    "         ]\n",
    "\n",
    "def createRestaurantPageLinks(self, response):\n",
    "   reviewsPerPage = 40\n",
    "   hxs = HtmlXPathSelector(response)\n",
    "   totalReviews = int(hxs.select('//h2[@id=\"total_reviews\"]/text()').extract()[0].strip().split(' ')[0])\n",
    "   pages = [Request(url=response.url + '?start=' + str(reviewsPerPage*(n+1)), \\\n",
    "                    callback=self.parse) \\\n",
    "            for n in range(totalReviews/reviewsPerPage)]\n",
    "   return pages\n",
    "\n",
    "def createReviewerPageLinks(self, response):\n",
    "   reviewsPerPage = 10\n",
    "   hxs = HtmlXPathSelector(response)\n",
    "   totalReviews = int(hxs.select('//div[@id=\"review_lister_header\"]/em/text()').extract()[0].split(' ')[0])\n",
    "   pages = [Request(url=response.url + '&rec_pagestart=' + str(reviewsPerPage*(n+1)), \\\n",
    "                    callback=self.parseReviewer) \\\n",
    "            for n in range(totalReviews/reviewsPerPage)]\n",
    "   return pages\n",
    "\n",
    "class HotelSpider(BaseSpider):\n",
    "   name = 'crawlHotels'\n",
    "   allowed_domains = ['bringfido.com']\n",
    "   start_urls = [ 'http://http://www.bringfido.com/lodging/city/{}'.format(s) for s in CITIES]\n",
    "\n",
    "   # default parse used for the landing page for each start_url\n",
    "   def parse(self, response):\n",
    "      requests = []\n",
    "\n",
    "      # extract all reviews from the page and return a list of requests for the 5 star reviewers' profiles\n",
    "      hxs = HtmlXPathSelector(response)\n",
    "      userIDs = [userUrl.split('?userid=')[1] for \\\n",
    "                 userUrl in hxs.select('//li[@class=\"user-name\"]/a/@href').extract()]\n",
    "      ratings = hxs.select('//div[@id=\"reviews-other\"]//meta[@itemprop=\"ratingValue\"]/@content').extract()\n",
    "   \n",
    "      for i in range(len(ratings)):\n",
    "         if float(ratings[i]) == 5:\n",
    "            requests.append(Request(url=URL_BASE + userIDs[i] + FILTER_SETTINGS, \\\n",
    "                                    callback=self.parseReviewer))\n",
    "   \n",
    "      # request additional pages if we are on page 1 of the restaurant\n",
    "      if response.url.find('?start=') == -1:\n",
    "         requests += createRestaurantPageLinks(self, response)\n",
    "\n",
    "      return requests\n",
    "      \n",
    "   # parse a given reviewer\n",
    "   def parseReviewer(self, response):\n",
    "      hxs = HtmlXPathSelector(response)\n",
    "      restaurantUrls = hxs.select('//div[@class=\"review clearfix\"]/ \\\n",
    "                                  div[@class=\"biz_info\"]/h4/a/@href').extract()\n",
    "      restaurants = [re.search(r'(?<=/biz/)[^#]*', rest).group() for rest in restaurantUrls]\n",
    "      reviewerName = hxs.select('//title/text()').extract()[0].split('|')[0].replace('\\'s Profile','').strip()\n",
    "      reviewerUserID = re.search(r'(?<=userid=)[^&]*', response.url).group()\n",
    "      ratingText = hxs.select('//div[@class=\"rating\"]/i/@title').extract()\n",
    "      ratings = [s.replace(' star rating','') for s in ratingText]\n",
    "\n",
    "      reviews = []\n",
    "      for i in range(len(restaurants)):\n",
    "         review = Review()\n",
    "         review['restaurant'] = restaurants[i]\n",
    "         review['reviewerName'] = reviewerName\n",
    "         review['reviewerUserID'] = reviewerUserID\n",
    "         review['rating'] = float(ratings[i])\n",
    "         reviews.append(review)\n",
    "\n",
    "      # request additional pages if we are on page 1 of the reviewer\n",
    "      additionalPages = []\n",
    "      if response.url.find('&rec_pagestart=') == -1:\n",
    "         additionalPages = createReviewerPageLinks(self, response)\n",
    "\n",
    "      return reviews + additionalPages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
